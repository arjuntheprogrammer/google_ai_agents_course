{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )\n\n# from kaggle_secrets import UserSecretsClient\n# user_secrets = UserSecretsClient()\n# secret_value_0 = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:04:41.935245Z","iopub.execute_input":"2025-11-12T10:04:41.936002Z","iopub.status.idle":"2025-11-12T10:04:42.006894Z","shell.execute_reply.started":"2025-11-12T10:04:41.935975Z","shell.execute_reply":"2025-11-12T10:04:42.005908Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:04:44.494788Z","iopub.execute_input":"2025-11-12T10:04:44.495111Z","iopub.status.idle":"2025-11-12T10:05:28.790085Z","shell.execute_reply.started":"2025-11-12T10:04:44.495078Z","shell.execute_reply":"2025-11-12T10:05:28.789168Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:05:28.791224Z","iopub.execute_input":"2025-11-12T10:05:28.792431Z","iopub.status.idle":"2025-11-12T10:05:28.797319Z","shell.execute_reply.started":"2025-11-12T10:05:28.792396Z","shell.execute_reply":"2025-11-12T10:05:28.796472Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:06:18.438374Z","iopub.execute_input":"2025-11-12T10:06:18.438824Z","iopub.status.idle":"2025-11-12T10:06:18.445678Z","shell.execute_reply.started":"2025-11-12T10:06:18.438790Z","shell.execute_reply":"2025-11-12T10:06:18.444898Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:06:21.677364Z","iopub.execute_input":"2025-11-12T10:06:21.678347Z","iopub.status.idle":"2025-11-12T10:06:21.684094Z","shell.execute_reply.started":"2025-11-12T10:06:21.678310Z","shell.execute_reply":"2025-11-12T10:06:21.683094Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:06:26.930627Z","iopub.execute_input":"2025-11-12T10:06:26.930942Z","iopub.status.idle":"2025-11-12T10:06:26.936817Z","shell.execute_reply.started":"2025-11-12T10:06:26.930917Z","shell.execute_reply":"2025-11-12T10:06:26.935847Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:06:53.238562Z","iopub.execute_input":"2025-11-12T10:06:53.238934Z","iopub.status.idle":"2025-11-12T10:07:01.892683Z","shell.execute_reply.started":"2025-11-12T10:06:53.238906Z","shell.execute_reply":"2025-11-12T10:07:01.891820Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are characterized by significant improvements in hardware, such as increased qubit stability and precision, alongside progress in quantum error correction. The field is shifting focus from merely increasing the number of qubits to enhancing their quality and performance. This evolution is paving the way for the practical application of quantum computing, with many expecting tangible results by 2025.\n\nThe implications for Artificial Intelligence (AI) are profound. Quantum computing is expected to revolutionize AI by enabling machine learning algorithms to process vast datasets at unprecedented speeds, thereby accelerating deep learning tasks and enhancing the ability to solve complex problems. This synergy, often referred to as \\\"Quantum AI,\\\" promises to unlock new levels of capability.\n\nSpecific industries stand to benefit immensely:\n*   **Healthcare:** Personalized medicine, faster drug discovery, and more accurate diagnostics through molecular-level simulations.\n*   **Chemicals and Materials Science:** Accelerated discovery of novel molecules and materials.\n*   **Mobility and Logistics:** Optimization of complex systems like traffic flow and supply chains.\n*   **Finance:** Development of sophisticated risk assessment models and fraud detection systems.\n\nDespite these exciting prospects, challenges such as hardware limitations and the need for integration with existing systems remain. However, the convergence of quantum computing and AI is set to redefine technological possibilities in the coming years.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:07:28.862301Z","iopub.execute_input":"2025-11-12T10:07:28.862992Z","iopub.status.idle":"2025-11-12T10:07:28.868370Z","shell.execute_reply.started":"2025-11-12T10:07:28.862965Z","shell.execute_reply":"2025-11-12T10:07:28.867518Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:07:36.030223Z","iopub.execute_input":"2025-11-12T10:07:36.031201Z","iopub.status.idle":"2025-11-12T10:07:36.036455Z","shell.execute_reply.started":"2025-11-12T10:07:36.031172Z","shell.execute_reply":"2025-11-12T10:07:36.035656Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:07:44.335483Z","iopub.execute_input":"2025-11-12T10:07:44.336300Z","iopub.status.idle":"2025-11-12T10:07:44.342003Z","shell.execute_reply.started":"2025-11-12T10:07:44.336265Z","shell.execute_reply":"2025-11-12T10:07:44.341137Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:07:49.497076Z","iopub.execute_input":"2025-11-12T10:07:49.497922Z","iopub.status.idle":"2025-11-12T10:07:49.502863Z","shell.execute_reply.started":"2025-11-12T10:07:49.497894Z","shell.execute_reply":"2025-11-12T10:07:49.501966Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:07:52.520530Z","iopub.execute_input":"2025-11-12T10:07:52.521252Z","iopub.status.idle":"2025-11-12T10:08:01.828074Z","shell.execute_reply.started":"2025-11-12T10:07:52.521226Z","shell.execute_reply":"2025-11-12T10:08:01.827242Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here is a blog outline about the benefits of multi-agent systems for software developers:\n\n## **Unleash Your Code's Potential: How Multi-Agent Systems Will Revolutionize Your Development**\n\nAre you tired of monolithic codebases that are a nightmare to manage, scale, and debug? Imagine a world where your software is composed of intelligent, independent agents, each handling a specific task with precision and adaptability. This isn't science fiction; it's the power of multi-agent systems (MAS), and they're poised to transform how you build software.\n\n### **1. Enhanced Modularity and Maintainability: Building Smarter, Not Harder**\n\n*   **Decomposition of Complexity:** MAS allows you to break down complex problems into smaller, manageable, and independent agent modules. This drastically reduces cognitive load and makes your codebase significantly easier to understand and modify.\n*   **Isolation and Fault Tolerance:** If one agent encounters an error or needs to be updated, it doesn't bring down the entire system. This isolation leads to greater robustness and simplifies the debugging process, allowing you to pinpoint and fix issues more efficiently.\n*   **Independent Development and Testing:** Teams can work on different agents concurrently without extensive interdependencies. This speeds up development cycles and enables more focused, unit-level testing for each agent.\n\n### **2. Increased Flexibility and Adaptability: Responding to the Ever-Changing World**\n\n*   **Dynamic System Evolution:** MAS can be designed to adapt to changing environments and requirements. New agents can be introduced, or existing ones modified or removed, without requiring a complete system overhaul.\n*   **Decentralized Decision-Making:** Agents can make local decisions based on their own knowledge and the information available to them, leading to more responsive and intelligent system behavior, especially in distributed or dynamic scenarios.\n*   **Scalability by Design:** As your application's needs grow, you can simply add more instances of existing agents or introduce new specialized agents to handle the increased load. This makes scaling more organic and less resource-intensive.\n\n### **3. Improved Collaboration and Coordination: When Software Works Together**\n\n*   **Emergent Behavior:** The interactions between multiple agents can lead to complex and sophisticated behaviors that are not explicitly programmed into any single agent. This allows for emergent intelligence and problem-solving capabilities.\n*   **Resource Optimization:** Agents can negotiate and coordinate their actions to efficiently share resources, avoid conflicts, and optimize overall system performance, much like a well-oiled team.\n*   **Specialized Expertise:** Each agent can be designed with specific expertise or responsibilities. This allows you to leverage specialized algorithms or functionalities within a cohesive system, leading to more powerful solutions.\n\n### **4. New Paradigms and Opportunities: Beyond Traditional Software Design**\n\n*   **Intelligent Automation:** MAS are ideal for automating complex tasks that require decision-making, learning, and interaction with dynamic environments, opening doors for advanced automation solutions.\n*   **Simulation and Modeling:** They provide a powerful framework for simulating complex systems, such as traffic flow, economic markets, or biological processes, allowing for deeper insights and predictive analysis.\n*   **Human-Agent Interaction:** MAS can facilitate more natural and intuitive interactions between humans and software, creating more engaging user experiences and intelligent assistants.\n\n### **Embrace the Future of Development**\n\nMulti-agent systems offer a powerful paradigm shift for software developers. By embracing modularity, flexibility, and intelligent collaboration, you can build more robust, adaptable, and sophisticated applications than ever before. Start exploring MAS today and unlock a new level of innovation in your software development journey.\nWriterAgent > ## Unleash Your Code's Potential: How Multi-Agent Systems Will Revolutionize Your Development\n\nAre you wrestling with monolithic codebases that feel like tangled spaghetti? Imagine software built from nimble, intelligent agents, each a master of its domain. This is the promise of multi-agent systems (MAS), and they're set to redefine how we develop.\n\nMAS fundamentally change how we approach complexity. By breaking down daunting problems into smaller, independent agents, we achieve unparalleled **modularity and maintainability**. Each agent tackles a specific task, making code easier to understand, modify, and crucially, debug. If one agent falters, the rest of the system remains resilient, a testament to their fault tolerance. Development teams can even work on agents concurrently, accelerating cycles and simplifying testing.\n\nBeyond structure, MAS offer remarkable **flexibility and adaptability**. Systems can evolve dynamically; new agents can be added or old ones updated without a full system overhaul. This decentralized decision-making allows for responsive behavior in ever-changing environments. Need to scale? Simply deploy more instances of existing agents or introduce specialized ones, making growth organic and efficient.\n\nFurthermore, MAS foster **improved collaboration and coordination**. Agents can interact, negotiate, and optimize resource usage, leading to emergent behaviors and collective intelligence. Think of it as a highly efficient team where each member brings specialized expertise.\n\nEmbracing MAS means stepping beyond traditional design. It unlocks potent possibilities for intelligent automation, sophisticated simulations, and more intuitive human-agent interactions. It's time to explore this powerful paradigm and build the next generation of software.\nEditorAgent > Okay, EditorAgent, I have refined the blog post based on the provided outline and the initial draft. My goal was to ensure grammatical correctness, improve flow, enhance clarity, and incorporate the key points from the outline into a cohesive narrative.\n\nHere is the revised blog post:\n\n## Unleash Your Code's Potential: How Multi-Agent Systems Will Revolutionize Your Development\n\nAre you tired of wrestling with monolithic codebases that feel like tangled spaghetti? Imagine building software from nimble, intelligent agents, each a master of its domain. This is the promise of multi-agent systems (MAS), and they are set to redefine how we develop.\n\n### Enhanced Modularity and Maintainability: Building Smarter, Not Harder\n\nMAS fundamentally change how we approach complexity. By breaking down daunting problems into smaller, independent agent modules, we achieve unparalleled **modularity and maintainability**. Each agent tackles a specific task, making code significantly easier to understand, modify, and, crucially, debug. This decomposition drastically reduces cognitive load.\n\nFurthermore, the isolation of agents provides remarkable **fault tolerance**. If one agent encounters an error or needs an update, it doesn't bring down the entire system. This resilience simplifies the debugging process, allowing for more efficient pinpointing and fixing of issues. Development teams can also work on different agents concurrently without extensive interdependencies, accelerating development cycles and enabling more focused, unit-level testing for each agent.\n\n### Increased Flexibility and Adaptability: Responding to the Ever-Changing World\n\nBeyond structure, MAS offer remarkable **flexibility and adaptability**. Systems can evolve dynamically; new agents can be introduced, or existing ones modified or removed, without requiring a complete system overhaul. This ability for dynamic system evolution is crucial in today's fast-paced environments.\n\nMAS excel in environments that demand responsive behavior. Their decentralized decision-making allows agents to make local choices based on their own knowledge and available information, leading to more intelligent and adaptive system behavior, especially in distributed or dynamic scenarios. Need to scale? Simply deploy more instances of existing agents or introduce new specialized ones to handle increased load. This makes scaling more organic and less resource-intensive.\n\n### Improved Collaboration and Coordination: When Software Works Together\n\nMAS foster **improved collaboration and coordination** among software components. Agents can interact, negotiate, and coordinate their actions to efficiently share resources, avoid conflicts, and optimize overall system performance. This leads to emergent behaviors and a form of collective intelligence that is not explicitly programmed into any single agent. Think of it as a highly efficient team where each member brings specialized expertise, working together to achieve a common goal.\n\n### New Paradigms and Opportunities: Beyond Traditional Software Design\n\nEmbracing MAS means stepping beyond traditional design patterns. It unlocks potent possibilities for intelligent automation, sophisticated simulations, and more intuitive human-agent interactions. They provide a powerful framework for complex task automation, modeling intricate systems like traffic flow or economic markets, and creating more engaging user experiences through intelligent assistants.\n\nIt's time to explore this powerful paradigm and build the next generation of software. Start embracing multi-agent systems today and unlock a new level of innovation in your development journey.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:08:29.904981Z","iopub.execute_input":"2025-11-12T10:08:29.905317Z","iopub.status.idle":"2025-11-12T10:08:29.911242Z","shell.execute_reply.started":"2025-11-12T10:08:29.905292Z","shell.execute_reply":"2025-11-12T10:08:29.910447Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:08:30.326235Z","iopub.execute_input":"2025-11-12T10:08:30.327335Z","iopub.status.idle":"2025-11-12T10:08:30.332809Z","shell.execute_reply.started":"2025-11-12T10:08:30.327303Z","shell.execute_reply":"2025-11-12T10:08:30.331814Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:08:34.483900Z","iopub.execute_input":"2025-11-12T10:08:34.484564Z","iopub.status.idle":"2025-11-12T10:08:34.490105Z","shell.execute_reply.started":"2025-11-12T10:08:34.484535Z","shell.execute_reply":"2025-11-12T10:08:34.489147Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:08:37.690049Z","iopub.execute_input":"2025-11-12T10:08:37.690398Z","iopub.status.idle":"2025-11-12T10:08:37.696568Z","shell.execute_reply.started":"2025-11-12T10:08:37.690371Z","shell.execute_reply":"2025-11-12T10:08:37.695649Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:09:20.116698Z","iopub.execute_input":"2025-11-12T10:09:20.117015Z","iopub.status.idle":"2025-11-12T10:09:20.122451Z","shell.execute_reply.started":"2025-11-12T10:09:20.116993Z","shell.execute_reply":"2025-11-12T10:09:20.121452Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:09:23.187560Z","iopub.execute_input":"2025-11-12T10:09:23.187898Z","iopub.status.idle":"2025-11-12T10:09:29.946941Z","shell.execute_reply.started":"2025-11-12T10:09:23.187875Z","shell.execute_reply":"2025-11-12T10:09:29.946034Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **AI/ML Trends: Key Developments, Companies, and Impact**\n\nThe artificial intelligence and machine learning landscape is rapidly evolving, with several key trends shaping its trajectory.\n\n**1. Generative AI Expansion:** Moving beyond text-based chatbots like ChatGPT, generative AI is increasingly used for creating complex multimedia content such as images, video, and music. Tools like Google's Imagen and Muse, and Stability AI's Stable Diffusion exemplify this trend. This advancement enhances creative expression and opens new practical applications across industries.\n\n**2. Rise of Agentic AI:** AI systems are becoming more autonomous, capable of performing tasks and making decisions with minimal human oversight. Companies like Salesforce are developing \"Agentforce\" to handle business workflows. This shift promises increased efficiency, particularly in areas like logistics and customer support.\n\n**3. Multimodal AI Integration:** This trend focuses on AI models that can process and combine data from various sources, including text, images, and audio. This capability leads to more effective outcomes, such as enhanced diagnostics in healthcare by integrating patient data with medical imaging.\n\n**Major Companies Involved:** Key players driving these advancements include **Google** (with Gemini and Imagen), **Microsoft** (Azure AI platform), **Amazon** (AWS, Alexa), **NVIDIA** (GPUs), **OpenAI**, **Meta Platforms**, **IBM**, and **Databricks**.\n\n**Potential Impact:** These AI/ML trends are set to revolutionize industries by automating processes, enhancing decision-making with data-driven insights, and creating new forms of content and interaction. However, they also raise important ethical considerations regarding bias, transparency, and the future of work, necessitating careful management and workforce adaptation. The overall economic impact is substantial, with projections indicating significant growth in the AI market.\nFinanceResearcher > Here's your executive briefing for November 12, 2025:\n\n**Technology:**\nBig tech firms continue to face challenges in the Industrial IoT space, with PTC selling off Kepware and ThingWorx. This highlights a recurring issue of major tech companies struggling to translate industrial IoT into growth, often leaving execution to specialized providers. In contrast, the DEA is significantly leveraging AI and machine learning for advancements in enforcement, from drug origin determination to AI-generated visuals for investigations.\n\n**Health:**\nThe \"Make America Healthy Again\" (MAHA) Summit will feature key figures like JD Vance and RFK Jr., alongside health tech CEOs from companies such as Google and Neuralink. Discussions will cover topics from healthier food in America to biohacking. Meanwhile, a significant trend in healthcare AI is the focus on deploying solutions into practical clinical workflows, with challenges in monitoring accuracy and managing change among staff.\n\n**Finance:**\nFinancial institutions are increasingly monitoring generative AI tools like ChatGPT, with a nearly 3,000% surge in firms capturing this data. This reflects a growing need for compliance and risk management across new communication channels. In banking, ANZ's CEO discussed plans to improve business banking performance by increasing frontline staff and enhancing digital tools, amidst a complex global economic landscape.\nHealthResearcher > Here's a summary of recent breakthroughs across Health, Tech, and Finance:\n\n**Health:**\n*   **mRNA Vaccines:** Revolutionizing vaccine development for faster creation and improved efficacy, with ongoing trials for new diseases like shingles.\n*   **AI in Diagnosis:** AI is beginning to outperform humans in diagnosing diseases from medical scans and predicting critical conditions.\n*   **Living Mitral Valve Replacement:** A pioneering surgery using donor valves offers a growing solution for pediatric heart conditions.\n\n**Tech:**\n*   **AI Advancements:** Large Language Models (LLMs) are moving beyond text generation into areas like protein development and scientific research.\n*   **Quantum Computing:** Rapid progress in algorithms and hardware points towards potential breakthroughs in cybersecurity, cryptography, and drug discovery, with commercial applications anticipated within the next few years.\n*   **Extended Reality (XR):** Projected market growth indicates widespread integration into gaming, education, training, and remote collaboration, blurring physical and virtual realities.\n\n**Finance:**\n*   **Embedded Finance:** Seamless integration of financial services into non-financial platforms is projected for significant growth by 2026, enhancing commerce and customer experience.\n*   **AI-Powered Personalization:** AI is central to FinTech, projected to significantly grow and enhance personalized services, contract review, and risk assessment.\n*   **Decentralized Finance (DeFi):** Maturing into a robust ecosystem with enhanced security and scalability, DeFi protocols are attracting users with improved liquidity and lower fees.\n\n**Estimated Timelines:**\n*   **Health:** mRNA vaccines continue to evolve, with new applications appearing regularly. AI in diagnosis is already in use and rapidly advancing. Living valve transplants are cutting-edge but show promise for wider application.\n*   **Tech:** AI and XR are seeing rapid integration and growth, with widespread adoption expected in the next 1-5 years. Quantum computing's practical applications are debated but expected within the next 5-10 years.\n*   **Finance:** Embedded finance and AI-driven personalization are current trends with significant growth expected in the next 1-2 years. DeFi's maturation is ongoing.\nAggregatorAgent > **Executive Summary: AI's Pervasive Impact Across Industries**\n\nArtificial intelligence is the dominant force shaping advancements across technology, health, and finance, driving innovation and presenting new challenges. Generative and multimodal AI are rapidly expanding their capabilities, moving beyond text to create multimedia content and integrate diverse data sources for enhanced outcomes. This is particularly evident in healthcare, where AI is revolutionizing diagnosis and drug development, complementing breakthroughs like mRNA vaccines and advanced surgical techniques.\n\nIn finance, AI-powered personalization and embedded finance are set for significant growth, while institutions are intensely monitoring generative AI for compliance and risk management. Concurrently, the DEA is leveraging AI for enforcement, highlighting its broad applicability. While big tech faces hurdles in industrial IoT, the overall trend indicates AI's transformative potential, promising increased efficiency and new applications, though ethical considerations and workforce adaptation remain critical. Quantum computing and XR also represent significant future tech developments.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:10:11.435057Z","iopub.execute_input":"2025-11-12T10:10:11.435423Z","iopub.status.idle":"2025-11-12T10:10:11.441154Z","shell.execute_reply.started":"2025-11-12T10:10:11.435398Z","shell.execute_reply":"2025-11-12T10:10:11.440106Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:10:12.605765Z","iopub.execute_input":"2025-11-12T10:10:12.606540Z","iopub.status.idle":"2025-11-12T10:10:12.611880Z","shell.execute_reply.started":"2025-11-12T10:10:12.606506Z","shell.execute_reply":"2025-11-12T10:10:12.610809Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:10:36.864404Z","iopub.execute_input":"2025-11-12T10:10:36.864747Z","iopub.status.idle":"2025-11-12T10:10:36.870725Z","shell.execute_reply.started":"2025-11-12T10:10:36.864723Z","shell.execute_reply":"2025-11-12T10:10:36.869297Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and a critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:10:53.248204Z","iopub.execute_input":"2025-11-12T10:10:53.248552Z","iopub.status.idle":"2025-11-12T10:10:53.254796Z","shell.execute_reply.started":"2025-11-12T10:10:53.248527Z","shell.execute_reply":"2025-11-12T10:10:53.253902Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:12:02.531977Z","iopub.execute_input":"2025-11-12T10:12:02.532686Z","iopub.status.idle":"2025-11-12T10:12:02.538293Z","shell.execute_reply.started":"2025-11-12T10:12:02.532648Z","shell.execute_reply":"2025-11-12T10:12:02.537469Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:12:05.487425Z","iopub.execute_input":"2025-11-12T10:12:05.487750Z","iopub.status.idle":"2025-11-12T10:12:12.651816Z","shell.execute_reply.started":"2025-11-12T10:12:05.487728Z","shell.execute_reply":"2025-11-12T10:12:12.651026Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias traced the salty lines etched into the weathered map. It had washed ashore with the tide, nestled amongst kelp and driftwood. The parchment, surprisingly intact, pulsed with an inner, phosphorescent glow. Strange symbols, unlike any he‚Äôd ever seen, shimmered across its surface. They weren't any language he recognized, not even the old mariners' scrawls he sometimes found. As he held it closer, the light intensified, casting an ethereal luminescence on the stone walls of his lighthouse. A faint hum vibrated through his fingertips. He‚Äôd spent forty years tending this lonely beacon, guiding ships through fog and storm. But this map‚Ä¶ this map promised a journey far beyond the familiar horizon.\nCriticAgent > The story begins with a strong hook, immediately introducing a mysterious artifact and an intriguing protagonist. Elias, the lighthouse keeper, feels established with his forty years of service, grounding him in his solitary life. The description of the map is evocative, hinting at its magical or otherworldly nature. The pacing is good, building suspense as Elias examines the map and its strange properties.\n\nHowever, the story feels like a prologue to something larger.\n\nHere are 2-3 specific, actionable suggestions for improvement:\n\n1.  **Expand on the 'journey' hinted at:** The map promises a journey, but the story ends just as this promise is made. To give the reader a more complete sense of narrative, introduce a concrete next step or a specific immediate consequence of Elias interacting with the map. For example, does the map reveal a location, or does it physically alter something in the lighthouse?\n2.  **Introduce an immediate sensory detail related to the journey:** While the phosphorescence and hum are good, adding another immediate sensory experience tied to the map's promise could heighten the intrigue. Does Elias smell a strange scent, feel a pull in a certain direction, or hear a distant, unfamiliar sound?\n3.  **Hint at Elias's internal motivation for wanting a journey:** While his life of forty years is described, giving a subtle glimpse into why a \"journey far beyond the familiar horizon\" would appeal to him (even if it's just a fleeting thought or a long-suppressed desire) would deepen his character and make his engagement with the map more resonant.\nRefinerAgent > Elias traced the salty lines etched into the weathered map. It had washed ashore with the tide, nestled amongst kelp and driftwood. The parchment, surprisingly intact, pulsed with an inner, phosphorescent glow. Strange symbols, unlike any he‚Äôd ever seen, shimmered across its surface. They weren't any language he recognized, not even the old mariners' scrawls he sometimes found. As he held it closer, the light intensified, casting an ethereal luminescence on the stone walls of his lighthouse. A faint hum vibrated through his fingertips, and with it, the sudden, inexplicable scent of star anise and ozone. A longing, buried for forty years of tending this lonely beacon, stirred within him ‚Äì a yearning for something more than fog and storm. The map wasn't just promising a journey; it was *pulling* him, a silent siren song in the form of glowing symbols. One particular symbol, a spiraling vortex, flared brighter, and Elias felt a distinct tug, as if the sea itself were urging him towards a specific, uncharted direction. He looked out at the vast, familiar expanse, then back at the impossible map. For the first time in decades, the horizon seemed to beckon not with duty, but with destiny.\nCriticAgent > The story has been significantly improved, incorporating the previous suggestions effectively.\n\n*   **Plot:** The plot now has a clearer direction with Elias feeling a direct \"pull\" from the map and a specific symbol (the vortex) activating this pull. The suggestion to hint at his internal motivation is also well-addressed by mentioning the \"longing, buried for forty years... a yearning for something more than fog and storm.\"\n*   **Characters:** Elias's character is solidified by the contrast between his long, dutiful service and this sudden, destiny-driven beckoning. The map itself has become a more active element, almost a character in its own right.\n*   **Pacing:** The pacing remains excellent, building intrigue and culminating in a moment of decision and burgeoning destiny. The addition of the star anise and ozone scent is a great sensory detail that enhances the mystery.\n\nThe story is well-written and feels much more complete as a snapshot of Elias's turning point.\n\nAPPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}